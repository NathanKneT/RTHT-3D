# RTHT-3D : Real-Time Hand Tracking 3D Art Project

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)

An interactive 3D art framework combining hand gesture recognition with a nostalgic Y2K aesthetic. This project enables users to manipulate 3D objects in a Blender environment using intuitive hand gestures captured through a webcam, inspired by futuristic interfaces from films like Minority Report.

![RTHT-3D Demo](docs/gif/demo.gif)

## âœ¨ Features

- Real-time hand tracking and gesture recognition using MediaPipe
- Interactive 3D environment with Y2K-inspired visuals
- Two-hand gesture support for advanced interactions
- Intuitive gestures: point to select, pinch to move, and more
- RGB color plane separation effects
- Sound feedback for interactions
- Client-server architecture connecting Python (vision) and Blender (3D)

## ğŸš€ Quick Start

### Prerequisites

- Python 3.7+
- Blender 2.93+ (3.x recommended)
- Webcam with clear view of your hands

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/y2k-art-project.git
   cd y2k-art-project
   ```

2. Install required Python dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Create necessary directories:
   ```bash
   mkdir -p sounds images
   ```

### Running the Project

1. Start the Blender environment:
   ```bash
   blender y2k_art_project.blend
   ```

2. In Blender, open the Scripting tab and run `blender_listener.py`

3. In a separate terminal, run the hand tracking module:
   ```bash
   python hand_tracking.py
   ```

4. Position your hands in view of the webcam and start interacting!

## ğŸ–ï¸ Gesture Guide

| Gesture | Hands | Action |
|---------|-------|--------|
| Point (index finger) | One | Select object |
| Pinch (thumb + index) | One | Move selected object |
| Pinch | Two | Rotate and scale object |
| V Sign | Two | Duplicate selected object |
| Palm | Two | Create new object |
| Fist | Two | Delete selected object |
| Palm + Pinch | Two | Toggle RGB separation effect |

## ğŸ§© Project Structure

```
project/
â”œâ”€â”€ hand_tracking.py        # Hand tracking and gesture recognition module
â”œâ”€â”€ Blender/
â”‚   â”œâ”€â”€ sounds/                 # Sound effect files (not provided)
â”‚   â”œâ”€â”€ images/                 # Custom images for texture mapping (not provided)
â”‚   â”œâ”€â”€ blender_listener.py     # Blender script for 3D environment and UDP listener
â”‚   â”œâ”€â”€ sandbox.blend           # Blender sandbox scene for testing
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ docs/                   # Documentation resources
â””â”€â”€ examples/               # Example configurations and outputs
```

## ğŸ› ï¸ Customization

### Adding Custom Images

Place your images in the `images/` directory to have them automatically loaded as textures for the 3D planes in Blender.

### Adjusting Y2K Aesthetics

Modify the `create_y2k_material()` function in `blender_listener.py` to customize:
- Colors and glow intensity
- Transparency effects
- Material properties

### Network Configuration

By default, the system uses `localhost:5006` for communication. To change:
1. Update `blender_address` in `hand_tracking.py`
2. Update `HOST` and `PORT` in `blender_listener.py`

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

### Development Setup

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Run the linter: `flake8 *.py`
5. Commit your changes: `git commit -m 'Add amazing feature'`
6. Push to the branch: `git push origin feature/amazing-feature`
7. Open a Pull Request

### Code Style

This project follows PEP 8 guidelines. Please ensure your code is properly formatted using:
```bash
black .
```

## ğŸ” Troubleshooting

### Common Issues

- **Socket Error**: Ensure no other application is using port 5006
- **No Hand Detection**: Check lighting conditions and camera position
- **Blender Not Responding**: Verify the Blender script is running properly
- **Missing Libraries**: Run `pip install -r requirements.txt` again

For more detailed troubleshooting, see the [Troubleshooting Guide](docs/troubleshooting.md).

## ğŸ“˜ Documentation

- [Installation Guide](docs/installation.md)
- [Gesture System](docs/gestures.md)
- [Blender Integration](docs/blender.md)
- [API Reference](docs/api.md)
- [Performance Optimization](docs/performance.md)

## ğŸ—ºï¸ Roadmap

- [ ] Additional gesture support
- [ ] VR/AR integration
- [ ] Animation recording and playback
- [ ] Custom shader effects library

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- MediaPipe team for the hand tracking technology
- Blender Foundation for the 3D creation platform
- All contributors who have helped shape this project

## ğŸ“¬ Contact

Project Link: [https://github.com/NathanKneT/RTHT-3D](https://github.com/NathanKneT/RTHT-3D)

Join our [Discord GLHF community](https://discord.gg/example) for discussions and support!